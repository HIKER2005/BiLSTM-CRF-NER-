"""
è®­ç»ƒBiLSTM+CRFæ¨¡å‹
"""

import torch
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
import os
import json
import time

from models.bilstm_crf import BiLSTM_CRF
from utils.data_loader import load_data, create_dataloader
from utils.vocab import Vocabulary
from utils.metrics import compute_metrics, compute_metrics_by_type


def train_epoch(model, dataloader, optimizer, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    batch_count = 0

    pbar = tqdm(dataloader, desc=f"Epoch {epoch} [Train]")

    for batch in pbar:
        words = batch['words'].to(device)
        tags = batch['tags'].to(device)
        lengths = batch['lengths']

        # åˆ›å»ºmask
        mask = torch.arange(words.size(1)).expand(len(lengths), -1).to(device) < lengths.unsqueeze(1)

        # å‰å‘ä¼ æ’­
        loss = model(words, tags, mask)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()

        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)

        optimizer.step()

        total_loss += loss.item()
        batch_count += 1

        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({'loss': f'{loss.item():.4f}'})

    return total_loss / batch_count


def evaluate(model, dataloader, vocab, device, epoch):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()

    all_true_tags = []
    all_pred_tags = []
    all_words = []

    pbar = tqdm(dataloader, desc=f"Epoch {epoch} [Eval]")

    with torch.no_grad():
        for batch in pbar:
            words = batch['words'].to(device)
            tags = batch['tags']
            lengths = batch['lengths']

            # åˆ›å»ºmask
            mask = torch.arange(words.size(1)).expand(len(lengths), -1).to(device) < lengths.unsqueeze(1)

            # é¢„æµ‹
            predictions = model(words, mask=mask)

            # è½¬æ¢å›æ ‡ç­¾
            for i, (pred, length) in enumerate(zip(predictions, lengths)):
                true_tag_seq = [vocab.get_tag(tags[i][j].item()) for j in range(length)]
                pred_tag_seq = [vocab.get_tag(tag_idx) for tag_idx in pred[:length]]
                word_seq = [vocab.get_word(words[i][j].item()) for j in range(length)]

                all_true_tags.append(true_tag_seq)
                all_pred_tags.append(pred_tag_seq)
                all_words.append(word_seq)

    # è®¡ç®—æŒ‡æ ‡
    metrics = compute_metrics(all_true_tags, all_pred_tags, all_words)
    metrics_by_type = compute_metrics_by_type(all_true_tags, all_pred_tags, all_words)

    return metrics, metrics_by_type


def save_checkpoint(model, optimizer, vocab, config, epoch, metrics, filepath):
    """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'vocab': vocab,
        'config': config,
        'metrics': metrics
    }, filepath)


def main():
    # è¶…å‚æ•°é…ç½®
    config = {
        'embedding_dim': 100,
        'hidden_dim': 256,
        'num_layers': 2,  # å¢åŠ åˆ°2å±‚LSTM
        'dropout': 0.5,
        'batch_size': 32,
        'num_epochs': 50,
        'learning_rate': 0.001,
        'weight_decay': 1e-5,  # L2æ­£åˆ™åŒ–
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'save_dir': 'checkpoints',
        'patience': 10,  # æ—©åœè€å¿ƒå€¼
    }

    print("=" * 70)
    print(" " * 20 + "BiLSTM+CRF è®­ç»ƒç¨‹åº")
    print("=" * 70)
    print("\né…ç½®å‚æ•°:")
    for key, value in config.items():
        print(f"  {key:20s}: {value}")
    print("=" * 70)

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists('data/train.txt'):
        print("\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ data/train.txt")
        print("è¯·å…ˆè¿è¡Œ python generate_data_with_deepseek.py ç”Ÿæˆæ•°æ®")
        return

    if not os.path.exists('data/test.txt'):
        print("\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶ data/test.txt")
        return

    # åŠ è½½æ•°æ®
    print("\nğŸ“ åŠ è½½æ•°æ®...")
    train_sentences, train_tags = load_data('data/train.txt')
    test_sentences, test_tags = load_data('data/test.txt')

    print(f"  è®­ç»ƒé›†: {len(train_sentences)} ä¸ªå¥å­")
    print(f"  æµ‹è¯•é›†: {len(test_sentences)} ä¸ªå¥å­")

    # æ„å»ºè¯è¡¨
    print("\nğŸ“š æ„å»ºè¯è¡¨...")
    vocab = Vocabulary()
    vocab.build_vocab(train_sentences, train_tags)
    print(f"  {vocab}")
    print(f"  æ ‡ç­¾: {[vocab.get_tag(i) for i in range(vocab.tag_size)]}")

    # åˆ›å»ºDataLoader
    print("\nğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader = create_dataloader(train_sentences, train_tags, vocab,
                                     config['batch_size'], shuffle=True)
    test_loader = create_dataloader(test_sentences, test_tags, vocab,
                                    config['batch_size'], shuffle=False)
    print(f"  è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}")
    print(f"  æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}")

    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ—ï¸  åˆ›å»ºæ¨¡å‹...")
    model = BiLSTM_CRF(
        vocab_size=vocab.vocab_size,
        tag_size=vocab.tag_size,
        embedding_dim=config['embedding_dim'],
        hidden_dim=config['hidden_dim'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )

    device = torch.device(config['device'])
    model.to(device)

    num_params = sum(p.numel() for p in model.parameters())
    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  æ€»å‚æ•°é‡: {num_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {num_trainable:,}")
    print(f"  è®¾å¤‡: {device}")

    # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    optimizer = optim.Adam(model.parameters(),
                           lr=config['learning_rate'],
                           weight_decay=config['weight_decay'])

    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5,
                                  patience=5)

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(config['save_dir'], exist_ok=True)

    # è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("=" * 70)

    best_f1 = 0
    patience_counter = 0
    train_history = []

    start_time = time.time()

    for epoch in range(1, config['num_epochs'] + 1):
        print(f"\n{'=' * 70}")
        print(f"Epoch {epoch}/{config['num_epochs']}")
        print(f"{'=' * 70}")

        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, device, epoch)

        # è¯„ä¼°
        metrics, metrics_by_type = evaluate(model, test_loader, vocab, device, epoch)

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(metrics['f1'])
        current_lr = optimizer.param_groups[0]['lr']

        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        print(f"ğŸ“Š å­¦ä¹ ç‡: {current_lr:.6f}")
        print(f"\næ•´ä½“æŒ‡æ ‡:")
        print(f"  ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.4f}")
        print(f"  å¬å›ç‡ (Recall):    {metrics['recall']:.4f}")
        print(f"  F1åˆ†æ•° (F1-Score):  {metrics['f1']:.4f}")
        print(f"  TP: {metrics['tp']}, FP: {metrics['fp']}, FN: {metrics['fn']}")

        print(f"\nå„ç±»å‹æŒ‡æ ‡:")
        print(f"  {'ç±»å‹':<8} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10} {'æ”¯æŒæ•°':<8}")
        print(f"  {'-' * 50}")
        for entity_type, scores in sorted(metrics_by_type.items()):
            print(f"  {entity_type:<8} {scores['precision']:<10.4f} "
                  f"{scores['recall']:<10.4f} {scores['f1']:<10.4f} "
                  f"{scores['support']:<8}")

        # è®°å½•å†å²
        train_history.append({
            'epoch': epoch,
            'train_loss': train_loss,
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1': metrics['f1'],
            'lr': current_lr
        })

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if metrics['f1'] > best_f1:
            best_f1 = metrics['f1']
            patience_counter = 0

            best_model_path = os.path.join(config['save_dir'], 'best_model.pt')
            save_checkpoint(model, optimizer, vocab, config, epoch, metrics, best_model_path)

            print(f"\nğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (F1={best_f1:.4f}) -> {best_model_path}")
        else:
            patience_counter += 1
            print(f"\nâ³ æœªæå‡ ({patience_counter}/{config['patience']})")

        # æ—©åœ
        if patience_counter >= config['patience']:
            print(f"\nâš ï¸  æ—©åœè§¦å‘ï¼å·²è¿ç»­{config['patience']}è½®æœªæå‡")
            break

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % 10 == 0:
            checkpoint_path = os.path.join(config['save_dir'], f'checkpoint_epoch_{epoch}.pt')
            save_checkpoint(model, optimizer, vocab, config, epoch, metrics, checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ -> {checkpoint_path}")

    # è®­ç»ƒå®Œæˆ
    total_time = time.time() - start_time
    print("\n" + "=" * 70)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print("=" * 70)
    print(f"  æ€»è€—æ—¶: {total_time / 60:.2f} åˆ†é’Ÿ")
    print(f"  æœ€ä½³F1: {best_f1:.4f}")
    print(f"  æœ€ç»ˆè½®æ¬¡: {epoch}")
    print(f"  æ¨¡å‹ä¿å­˜åœ¨: {config['save_dir']}/best_model.pt")

    # ä¿å­˜è®­ç»ƒå†å²
    history_path = os.path.join(config['save_dir'], 'train_history.json')
    with open(history_path, 'w', encoding='utf-8') as f:
        json.dump(train_history, f, indent=2, ensure_ascii=False)
    print(f"  è®­ç»ƒå†å²: {history_path}")

    print("\nä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œ python predict.py è¿›è¡Œé¢„æµ‹")
    print("  2. è¿è¡Œ python demo.py å¯åŠ¨äº¤äº’å¼æ¼”ç¤º")
    print("  3. è¿è¡Œ python visualize.py æŸ¥çœ‹å¯è§†åŒ–")
    print("=" * 70)


if __name__ == '__main__':
    main()