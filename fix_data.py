"""
ä¿®å¤è®­ç»ƒæ•°æ®çš„æ ‡æ³¨æ ¼å¼é—®é¢˜
"""

import re
from collections import defaultdict


def fix_tag_format(tag):
    """ç»Ÿä¸€æ ‡æ³¨æ ¼å¼ä¸º B-TYPE / I-TYPE / O"""
    if tag == 'O':
        return 'O'

    # å¤„ç† PER-B, LOC-I è¿™ç§æ ¼å¼ (é¢ å€’æ ¼å¼)
    if re.match(r'^(PER|LOC|ORG)-([BI])$', tag):
        entity_type, prefix = tag.split('-')
        return f'{prefix}-{entity_type}'

    # å¤„ç† PER, LOC, ORG è¿™ç§æ— å‰ç¼€æ ¼å¼
    if tag in ['PER', 'LOC', 'ORG']:
        return f'B-{tag}'  # å‡è®¾æ˜¯å¼€å§‹

    # å¤„ç† BMES æ ¼å¼
    if re.match(r'^[BME]-(PER|LOC|ORG)$', tag):
        prefix, entity_type = tag.split('-')
        if prefix in ['B']:
            return f'B-{entity_type}'
        else:  # M, E éƒ½å½“ä½œ I
            return f'I-{entity_type}'

    # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
    if re.match(r'^[BI]-(PER|LOC|ORG)$', tag):
        return tag

    # å…¶ä»–æƒ…å†µè¿”å› O
    return 'O'


def fix_entity_boundaries(words, tags):
    """ä¿®å¤å®ä½“è¾¹ç•Œé”™è¯¯"""
    fixed_tags = []
    i = 0

    while i < len(tags):
        tag = tags[i]

        # å¤„ç† B- æ ‡ç­¾åé¢åº”è¯¥æ˜¯ I- çš„æƒ…å†µ
        if tag.startswith('B-'):
            entity_type = tag[2:]
            fixed_tags.append(tag)
            i += 1

            # æ£€æŸ¥åç»­æ ‡ç­¾
            while i < len(tags):
                next_tag = tags[i]

                # å¦‚æœæ˜¯åŒç±»å‹çš„ B-ï¼Œè¯´æ˜ä¸Šä¸€ä¸ªå®ä½“ç»“æŸäº†
                if next_tag == f'B-{entity_type}':
                    break

                # å¦‚æœæ˜¯å…¶ä»– B- æˆ– Oï¼Œè¯´æ˜å®ä½“ç»“æŸ
                if next_tag.startswith('B-') or next_tag == 'O':
                    break

                # ä¿®æ­£ä¸º I-TYPE
                if next_tag in [f'I-{entity_type}', entity_type, f'{entity_type}-I']:
                    fixed_tags.append(f'I-{entity_type}')
                else:
                    break

                i += 1
        else:
            fixed_tags.append(tag if tag == 'O' else 'O')
            i += 1

    return fixed_tags


def clean_data_file(input_file, output_file):
    """æ¸…æ´—æ•°æ®æ–‡ä»¶"""
    print(f"\nğŸ”„ å¤„ç†æ–‡ä»¶: {input_file}")

    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # ç»Ÿè®¡é—®é¢˜
    format_errors = defaultdict(int)
    boundary_errors = 0
    total_sentences = 0
    total_tokens = 0

    # è§£ææ•°æ®
    sentences = []
    current_words = []
    current_tags = []

    for line in lines:
        line = line.strip()
        if not line:
            if current_words:
                sentences.append((current_words, current_tags))
                current_words = []
                current_tags = []
            continue

        parts = line.split()
        if len(parts) == 2:
            word, tag = parts
            current_words.append(word)
            current_tags.append(tag)

    if current_words:
        sentences.append((current_words, current_tags))

    print(f"  åŸå§‹å¥å­æ•°: {len(sentences)}")

    # æ¸…æ´—æ•°æ®
    cleaned_sentences = []

    for words, tags in sentences:
        total_sentences += 1
        total_tokens += len(words)

        # 1. ä¿®å¤æ ‡æ³¨æ ¼å¼
        fixed_format_tags = []
        for tag in tags:
            original_tag = tag
            fixed_tag = fix_tag_format(tag)
            if original_tag != fixed_tag:
                format_errors[original_tag] += 1
            fixed_format_tags.append(fixed_tag)

        # 2. ä¿®å¤å®ä½“è¾¹ç•Œ
        fixed_tags = fix_entity_boundaries(words, fixed_format_tags)

        # 3. éªŒè¯æ ‡æ³¨åˆæ³•æ€§
        valid = True
        for i, tag in enumerate(fixed_tags):
            # I- æ ‡ç­¾å¿…é¡»è·Ÿåœ¨ B- æˆ– I- åé¢
            if tag.startswith('I-'):
                entity_type = tag[2:]
                if i == 0 or (not fixed_tags[i - 1].endswith(f'-{entity_type}')):
                    fixed_tags[i] = f'B-{entity_type}'  # ä¿®æ­£ä¸º B-
                    boundary_errors += 1

        cleaned_sentences.append((words, fixed_tags))

    # å†™å…¥æ¸…æ´—åçš„æ•°æ®
    with open(output_file, 'w', encoding='utf-8') as f:
        for words, tags in cleaned_sentences:
            for word, tag in zip(words, tags):
                f.write(f'{word} {tag}\n')
            f.write('\n')

    print(f"  âœ… æ¸…æ´—åå¥å­æ•°: {len(cleaned_sentences)}")
    print(f"  ğŸ“Š æ ¼å¼é”™è¯¯ä¿®å¤: {sum(format_errors.values())} å¤„")
    if format_errors:
        print(f"     é”™è¯¯ç±»å‹åˆ†å¸ƒ:")
        for error_tag, count in sorted(format_errors.items(), key=lambda x: -x[1])[:10]:
            print(f"       {error_tag}: {count} æ¬¡")
    print(f"  ğŸ“Š è¾¹ç•Œé”™è¯¯ä¿®å¤: {boundary_errors} å¤„")
    print(f"  ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")


def main():
    print("=" * 70)
    print(" " * 20 + "æ•°æ®æ¸…æ´—å·¥å…·")
    print("=" * 70)

    # æ¸…æ´—è®­ç»ƒé›†
    clean_data_file('data/train.txt', 'data/train_cleaned.txt')

    # æ¸…æ´—æµ‹è¯•é›†
    clean_data_file('data/test.txt', 'data/test_cleaned.txt')

    print("\n" + "=" * 70)
    print("âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼")
    print("=" * 70)
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. å¤‡ä»½åŸå§‹æ•°æ®:")
    print("     mv data/train.txt data/train_original.txt")
    print("     mv data/test.txt data/test_original.txt")
    print("\n  2. ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®:")
    print("     mv data/train_cleaned.txt data/train.txt")
    print("     mv data/test_cleaned.txt data/test.txt")
    print("\n  3. é‡æ–°è®­ç»ƒæ¨¡å‹:")
    print("     python train.py")
    print("=" * 70)


if __name__ == '__main__':
    main()