"""
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
"""

import torch
from models.bilstm_crf import BiLSTM_CRF
from utils.metrics import extract_entities


def load_model(checkpoint_path='checkpoints/best_model.pt', device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    if not torch.cuda.is_available() and device == 'cuda':
        device = 'cpu'

    # ä¿®æ”¹è¿™é‡Œï¼šæ·»åŠ  weights_only=False
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    vocab = checkpoint['vocab']
    config = checkpoint['config']

    model = BiLSTM_CRF(
        vocab_size=vocab.vocab_size,
        tag_size=vocab.tag_size,
        embedding_dim=config['embedding_dim'],
        hidden_dim=config['hidden_dim'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )

    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    return model, vocab, config


def predict_sentence(model, vocab, sentence, device='cpu'):
    """
    é¢„æµ‹å•ä¸ªå¥å­

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        vocab: è¯è¡¨
        sentence: stræˆ–List[str] - è¾“å…¥å¥å­
        device: è®¾å¤‡

    Returns:
        words: List[str] - åˆ†è¯ç»“æœ
        tags: List[str] - æ ‡ç­¾åºåˆ—
        entities: List[tuple] - æå–çš„å®ä½“
    """
    # å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²ï¼Œè¿›è¡Œåˆ†è¯ï¼ˆç®€å•æŒ‰å­—ç¬¦åˆ†ï¼‰
    if isinstance(sentence, str):
        words = list(sentence.replace(' ', ''))
    else:
        words = sentence

    # è½¬æ¢ä¸ºç´¢å¼•
    word_indices = [vocab.get_word_idx(word) for word in words]
    words_tensor = torch.tensor([word_indices], dtype=torch.long).to(device)

    # é¢„æµ‹
    with torch.no_grad():
        predictions = model(words_tensor)

    # è½¬æ¢å›æ ‡ç­¾
    tags = [vocab.get_tag(tag_idx) for tag_idx in predictions[0]]

    # æå–å®ä½“
    entities = extract_entities(tags, words)

    return words, tags, entities


def predict_batch(model, vocab, sentences, device='cpu'):
    """
    æ‰¹é‡é¢„æµ‹

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        vocab: è¯è¡¨
        sentences: List[str] - å¥å­åˆ—è¡¨
        device: è®¾å¤‡

    Returns:
        results: List[dict] - é¢„æµ‹ç»“æœåˆ—è¡¨
    """
    results = []

    for sentence in sentences:
        words, tags, entities = predict_sentence(model, vocab, sentence, device)
        results.append({
            'sentence': sentence,
            'words': words,
            'tags': tags,
            'entities': entities
        })

    return results


def main():
    """ä¸»å‡½æ•° - æµ‹è¯•é¢„æµ‹åŠŸèƒ½"""
    import os

    print("=" * 70)
    print(" " * 20 + "BiLSTM+CRF é¢„æµ‹ç¨‹åº")
    print("=" * 70)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'checkpoints/best_model.pt'
    if not os.path.exists(model_path):
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        print("è¯·å…ˆè¿è¡Œ python train.py è®­ç»ƒæ¨¡å‹")
        return

    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model, vocab, config = load_model(model_path, device)

    print(f"  è®¾å¤‡: {device}")
    print(f"  è¯è¡¨å¤§å°: {vocab.vocab_size}")
    print(f"  æ ‡ç­¾æ•°é‡: {vocab.tag_size}")
    print(f"  æ ‡ç­¾: {[vocab.get_tag(i) for i in range(vocab.tag_size)]}")

    # æµ‹è¯•å¥å­
    test_sentences = [
        "æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨",
        "ä¹”å¸ƒæ–¯åˆ›ç«‹äº†è‹¹æœå…¬å¸",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
        "åˆ˜å¾·åæ¥è‡ªé¦™æ¸¯",
        "é©¬äº‘åœ¨æ­å·åˆ›åŠäº†é˜¿é‡Œå·´å·´é›†å›¢",
        "æ¸…åå¤§å­¦ä½äºåŒ—äº¬æµ·æ·€åŒº",
        "å§šæ˜æ˜¯è‘—åçš„ç¯®çƒè¿åŠ¨å‘˜",
        "åä¸ºå…¬å¸æ€»éƒ¨åœ¨æ·±åœ³",
    ]

    print("\n" + "=" * 70)
    print("ğŸ” å¼€å§‹é¢„æµ‹...")
    print("=" * 70)

    for i, sentence in enumerate(test_sentences, 1):
        print(f"\n[{i}] å¥å­: {sentence}")
        print("-" * 70)

        words, tags, entities = predict_sentence(model, vocab, sentence, device)

        # æ˜¾ç¤ºæ ‡æ³¨ç»“æœï¼ˆè¡¨æ ¼å½¢å¼ï¼‰
        print("\næ ‡æ³¨ç»“æœ:")
        print(f"  {'å­—ç¬¦':<5} {'æ ‡ç­¾':<10}")
        print(f"  {'-' * 20}")
        for word, tag in zip(words, tags):
            print(f"  {word:<5} {tag:<10}")

        # æ˜¾ç¤ºæå–çš„å®ä½“
        if entities:
            print("\nâœ… æå–çš„å®ä½“:")
            for start, end, entity_type, entity_text in entities:
                print(f"  [{entity_type}] {entity_text} (ä½ç½®: {start}:{end})")
        else:
            print("\nâŒ æœªè¯†åˆ«åˆ°å®ä½“")

        print("=" * 70)

    print("\nâœ… é¢„æµ‹å®Œæˆï¼")
    print("\næç¤º: è¿è¡Œ python demo.py å¯åŠ¨äº¤äº’å¼é¢„æµ‹ç•Œé¢")


if __name__ == '__main__':
    main()